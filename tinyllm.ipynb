{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cyFou/testColab/blob/main/tinyllm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ful9_femXKTv"
      },
      "source": [
        "Source du tuto\n",
        "https://levelup.gitconnected.com/building-a-perfect-million-parameter-llm-like-chatgpt-in-python-3b16e26b4139\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a6mcGGTOGMS_"
      },
      "source": [
        "# Creation du fichier jeu de données"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p8RxLchItBQ9",
        "outputId": "7ca7203a-79a8-44db-a5a6-b417be94f266"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-03-30 14:56:33--  https://www.modelscope.cn/datasets/deepctrl/deepctrl-sft-data/resolve/master/sft_data_fr.jsonl\n",
            "Resolving www.modelscope.cn (www.modelscope.cn)... 47.92.141.220, 39.99.133.195\n",
            "Connecting to www.modelscope.cn (www.modelscope.cn)|47.92.141.220|:443... connected.\n",
            "HTTP request sent, awaiting response... 404 \n",
            "2025-03-30 14:56:34 ERROR 404: (no description).\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# faire un ctrl C en fonction de la taille souhaité du jdd\n",
        "!wget https://www.modelscope.cn/datasets/deepctrl/deepctrl-sft-data/resolve/master/sft_data_fr.jsonl\n",
        "\n",
        "# import os,urllib\n",
        "# url = 'https://www.modelscope.cn/datasets/deepctrl/deepctrl-sft-data/resolve/master/sft_data_en.jsonl'\n",
        "# filename = './sft_data_en.jsonl'\n",
        "# if not os.path.isfile(filename):\n",
        "#     urllib.request.urlretrieve(url, filename)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LR9ig_9zGG3G"
      },
      "outputs": [],
      "source": [
        "# Supprimer la dernière ligne du fichier sft_data_en.jsonl car mal formaté du fait du Ctrl C\n",
        "def remove_last_line(filepath):\n",
        "    \"\"\"Removes the last line of a large file efficiently.\n",
        "\n",
        "    Args:\n",
        "      filepath: The path to the file.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        with open(filepath, 'rb+') as f:\n",
        "            f.seek(-2, os.SEEK_END)  # Go to the second-to-last byte\n",
        "            while f.read(1) != b'\\n':\n",
        "                f.seek(-2, os.SEEK_CUR)  # Back up two bytes\n",
        "                if f.tell() == 0:\n",
        "                    # Handle the case where there's only one line or no newline chars.\n",
        "                    f.truncate(0)\n",
        "                    return\n",
        "            f.truncate()\n",
        "    except OSError as e:\n",
        "        print(f\"Error removing last line from {filepath}: {e}\")\n",
        "        return\n",
        "\n",
        "remove_last_line(\"sft_data_en.jsonl\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xBmPTblYtEvG"
      },
      "outputs": [],
      "source": [
        "# Supprimer la dernière ligne du fichier sft_data_en.jsonl car mal formaté du fait du Ctrl C\n",
        "!sed -i '$d' sft_data_en.jsonl\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "08DuV4orGG3I"
      },
      "outputs": [],
      "source": [
        "# import json\n",
        "# from tqdm import tqdm\n",
        "\n",
        "# file_path = \"sft_data_en.jsonl\" # Downloaded filepath (23 GB RAM REQUIRED!!!!!!!!!!!!!!!!!!!!!)\n",
        "\n",
        "# # Read the JSONL file with tqdm progress bar\n",
        "# data = []\n",
        "# with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
        "#     # Iterate through each line of the JSONL file\n",
        "#     for line in tqdm(file, desc=\"Loading JSONL file\"):\n",
        "#         # Parse each line as a JSON object and append to data\n",
        "#         data.append(json.loads(line))\n",
        "\n",
        "# print(len(data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SKIpX2vWuPdP",
        "outputId": "049a2987-cc64-490a-a328-1173d3745d17"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Filter JSONL file: 48459it [00:01, 26400.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New JSONL file saved as petrain_data.jsonl\n",
            "3122\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "##### retravaille le fichier de données : ligne de 512 caratère, supression (en grande partie) des lignes avec caratère asiatique\n",
        "\n",
        "import json\n",
        "from tqdm import tqdm\n",
        "import re\n",
        "\n",
        "file_path = \"sft_data_en.jsonl\"\n",
        "\n",
        "# Define the output file name\n",
        "output_file = \"petrain_data.jsonl\"\n",
        "\n",
        "lenAfterFilter = 0\n",
        "# Write data to JSONL format\n",
        "asian_char_pattern = re.compile(r'[\\u4E00-\\u9FFF\\u3040-\\u30FF\\uAC00-\\uD7AF]')\n",
        "with open(file_path, 'r', encoding='utf-8') as infile, open(output_file, 'w', encoding='utf-8') as outfile:\n",
        "    for line in tqdm(infile, desc=\"Filter JSONL file\"):\n",
        "        item = json.loads(line)\n",
        "        io_length = len(item['input']) + len(item['output'])\n",
        "        if io_length < 512 and not asian_char_pattern.search(line):\n",
        "            json.dump({\"text\": f\"{item['input']}\\n{item['output']}\"}, outfile, ensure_ascii=False)\n",
        "            outfile.write(\"\\n\")  # Newline for each JSONL entry\n",
        "            lenAfterFilter+=1\n",
        "print(f\"New JSONL file saved as {output_file}\")\n",
        "print(lenAfterFilter)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cF9YBGBGGUU0"
      },
      "source": [
        "# Creation du dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ub0zYwlbGG3K"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import AutoTokenizer\n",
        "import json\n",
        "from tqdm import tqdm\n",
        "import re\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wD1V_40nGG3L"
      },
      "outputs": [],
      "source": [
        "class PretrainDataset(Dataset):\n",
        "    \"\"\"Dataset for pretraining.\"\"\"\n",
        "\n",
        "    def __init__(self, data_path, tokenizer, max_length=512):\n",
        "        \"\"\"\n",
        "        Initializes the PretrainDataset.\n",
        "\n",
        "        Args:\n",
        "            data_path (str): Path to the JSONL data file.\n",
        "            tokenizer: The tokenizer to use.\n",
        "            max_length (int): Maximum sequence length.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "        self.samples = self.load_data(data_path)\n",
        "\n",
        "    def load_data(self, path):\n",
        "        \"\"\"\n",
        "        Loads data from a JSONL file.\n",
        "\n",
        "        Args:\n",
        "            path (str): Path to the JSONL file.\n",
        "\n",
        "        Returns:\n",
        "            list: A list of samples loaded from the file.\n",
        "        \"\"\"\n",
        "        samples = []\n",
        "        with open(path, 'r', encoding='utf-8') as f:\n",
        "            for line_num, line in enumerate(f, 1):  # enumerate starts at 1 for line_num\n",
        "                data = json.loads(line.strip())\n",
        "                samples.append(data)\n",
        "        return samples\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"Returns the number of samples in the dataset.\"\"\"\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        \"\"\"\n",
        "        Retrieves a sample from the dataset.\n",
        "\n",
        "        Args:\n",
        "            index (int): Index of the sample to retrieve.\n",
        "\n",
        "        Returns:\n",
        "            tuple: A tuple containing the input (X), target (Y), and loss mask.\n",
        "        \"\"\"\n",
        "        sample = self.samples[index]\n",
        "\n",
        "        # Construct the input text, including BOS and EOS tokens.\n",
        "        text = f\"{self.tokenizer.bos_token}{str(sample['text'])}{self.tokenizer.eos_token}\"\n",
        "        encoding = self.tokenizer(\n",
        "            text,\n",
        "            max_length=self.max_length,\n",
        "            padding='max_length',  # Pad to max_length\n",
        "            truncation=True,  # Truncate to max_length\n",
        "            return_tensors='pt'  # Return PyTorch tensors\n",
        "        )\n",
        "        input_ids = encoding.input_ids.squeeze()  # Remove extra dimension\n",
        "        loss_mask = (input_ids != self.tokenizer.pad_token_id)  # Create loss mask (ignore padding)\n",
        "\n",
        "        # Create input (X) and target (Y) tensors, shifting by one position.\n",
        "        X = input_ids[:-1].clone()\n",
        "        Y = input_ids[1:].clone()\n",
        "        loss_mask = loss_mask[1:].clone()  # Shift loss mask as well\n",
        "        return X, Y, loss_mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vI_EhrTeGG3L"
      },
      "outputs": [],
      "source": [
        "# # Configuration for our Transformer model\n",
        "# model_config = {\n",
        "#     \"vocab_size\": 6400,       # Size of the vocabulary\n",
        "#     \"dim\": 512,               # Dimensionality of the embeddings and hidden states\n",
        "#     \"n_heads\": 8,             # Number of attention heads\n",
        "#     \"n_kv_heads\": 2,          # Number of key-value heads (as specified in the LMConfig)\n",
        "#     \"norm_eps\": 1e-5,         # Epsilon for RMSNorm\n",
        "#     \"dropout\": 0.0,           # Dropout probability\n",
        "#     \"max_seq_len\": 1024,      # Maximum sequence length\n",
        "#     \"rope_theta\": 10000.0,    # Theta parameter for RoPE\n",
        "#     \"multiple_of\": 64,        # Used for hidden dimension calculation in FFN\n",
        "#     \"hidden_dim\": None,       # Hidden dimension of the FFN (calculated if None)\n",
        "#     \"n_layers\": 8,            # Number of Transformer blocks\n",
        "#     \"flash_attn\": True,       # Use flash attention if available\n",
        "# }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zv4O5htUGG3M"
      },
      "outputs": [],
      "source": [
        "\n",
        "# tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
        "# tokenizer.add_bos_token = False\n",
        "# tokenizer.add_eos_token = False\n",
        "# tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
        "\n",
        "# # Create the training dataset\n",
        "# train_ds = PretrainDataset(\"petrain_data.jsonl\", tokenizer, max_length=model_config[\"max_seq_len\"])\n",
        "\n",
        "# # Create the data loader\n",
        "# train_loader = DataLoader(train_ds, batch_size=32, shuffle=True, drop_last=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cQIuPHRPGG3M"
      },
      "outputs": [],
      "source": [
        "# x,y,mask = next(iter(train_ds))\n",
        "# print(x.shape)\n",
        "# print(y.shape)\n",
        "# print(mask.shape)\n",
        "# print(\"x=>\",x)\n",
        "# print(\"y=>\",y)\n",
        "# print(\"x=>\",tokenizer.decode(x))\n",
        "# print(\"y=>\",tokenizer.decode(y))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RPNOVR4JGb4u"
      },
      "source": [
        "# Creation du model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FQDAZ4YNPEl1"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch import nn\n",
        "from transformers import PreTrainedModel\n",
        "from transformers.modeling_outputs import CausalLMOutputWithPast\n",
        "from typing import Optional, Tuple, List\n",
        "from transformers import PretrainedConfig\n",
        "\n",
        "class LMConfig(PretrainedConfig):\n",
        "    \"\"\"\n",
        "    Configuration class for the language model.  Inherits from PretrainedConfig.\n",
        "    This configuration class stores all the hyperparameters of the model.\n",
        "\n",
        "    Attributes:\n",
        "        model_type (str): Model type identifier.\n",
        "        dim (int): Embedding dimension.\n",
        "        n_layers (int): Number of transformer layers.\n",
        "        n_heads (int): Number of attention heads.\n",
        "        n_kv_heads (int): Number of key-value attention heads (for multi-query attention).\n",
        "        vocab_size (int): Size of the vocabulary.\n",
        "        hidden_dim (int, optional): Hidden dimension of the feedforward network.\n",
        "            If None, it's calculated based on `dim` and `multiple_of`.\n",
        "        multiple_of (int): Used to calculate `hidden_dim` if `hidden_dim` is None.\n",
        "        norm_eps (float): Epsilon value for layer normalization.\n",
        "        max_seq_len (int): Maximum sequence length.\n",
        "        rope_theta (int): Theta value for rotary positional embeddings.\n",
        "        dropout (float): Dropout probability.\n",
        "        flash_attn (bool): Whether to use Flash Attention (if available).\n",
        "        use_moe (bool): Whether to use Mixture of Experts.\n",
        "        num_experts_per_tok (int): Number of experts per token (only if use_moe is True).\n",
        "        n_routed_experts (int): Total number of experts (only if use_moe is True).\n",
        "        n_shared_experts (bool): Whether to use shared experts (only if use_moe is True).\n",
        "        scoring_func (str): Scoring function for expert selection (only if use_moe is True).\n",
        "        aux_loss_alpha (float): Weight for the auxiliary loss (only if use_moe is True).\n",
        "        seq_aux (bool): Whether to compute aux loss at sequence level (only if use_moe is True).\n",
        "        norm_topk_prob (bool): Whether to normalize top-k probabilities (only if use_moe is True).\n",
        "    \"\"\"\n",
        "\n",
        "    model_type = \"transformerlm\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        dim: int = 512,             # Embedding dimension\n",
        "        n_layers: int = 8,           # Number of transformer layers\n",
        "        n_heads: int = 8,           # Number of attention heads\n",
        "        n_kv_heads: int = 2,        # Number of key-value heads (multi-query attention)\n",
        "        vocab_size: int = 6400,     # Size of the vocabulary\n",
        "        hidden_dim: int = None,     # Hidden dimension of the FFN (calculated if None)\n",
        "        multiple_of: int = 64,      # Used for calculating hidden_dim\n",
        "        norm_eps: float = 1e-5,     # Epsilon value for layer normalization\n",
        "        max_seq_len: int = 1024,    # Maximum sequence length\n",
        "        rope_theta: int = 1e6,      # Theta for RoPE\n",
        "        dropout: float = 0.0,       # Dropout probability\n",
        "        flash_attn: bool = True,    # Use Flash Attention if available\n",
        "        num_experts_per_tok: int = 2, # Number of experts per token (unused)\n",
        "        n_routed_experts: int = 4,   # Total number of experts (unused)\n",
        "        n_shared_experts: bool = True,# Use shared experts (unused)\n",
        "        scoring_func: str = \"softmax\",# Expert scoring function (unused)\n",
        "        aux_loss_alpha: float = 0.1, # Weight for auxiliary loss (unused)\n",
        "        seq_aux: bool = True,        # Sequence-level auxiliary loss (unused)\n",
        "        norm_topk_prob: bool = True, # Normalize top-k probabilities (unused)\n",
        "        **kwargs,\n",
        "    ):\n",
        "        self.dim = dim\n",
        "        self.n_layers = n_layers\n",
        "        self.n_heads = n_heads\n",
        "        self.n_kv_heads = n_kv_heads\n",
        "        self.vocab_size = vocab_size\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.multiple_of = multiple_of\n",
        "        self.norm_eps = norm_eps\n",
        "        self.max_seq_len = max_seq_len\n",
        "        self.rope_theta = rope_theta\n",
        "        self.dropout = dropout\n",
        "        self.flash_attn = flash_attn\n",
        "        self.num_experts_per_tok = num_experts_per_tok\n",
        "        self.n_routed_experts = n_routed_experts\n",
        "        self.n_shared_experts = n_shared_experts\n",
        "        self.scoring_func = scoring_func\n",
        "        self.aux_loss_alpha = aux_loss_alpha\n",
        "        self.seq_aux = seq_aux\n",
        "        self.norm_topk_prob = norm_topk_prob\n",
        "\n",
        "        super().__init__(**kwargs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ds9876IQGG3N"
      },
      "outputs": [],
      "source": [
        "class RMSNorm(torch.nn.Module):\n",
        "    def __init__(self, dim: int, eps: float):\n",
        "        super().__init__()\n",
        "        self.eps = eps  # Small constant for numerical stability\n",
        "        self.weight = nn.Parameter(torch.ones(dim)) # Learnable scaling parameter\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Calculate the root mean square (RMS) and normalize\n",
        "        return self.weight * (x.float() * torch.rsqrt(x.pow(2).mean(-1, keepdim=True) + self.eps)).type_as(x)\n",
        "\n",
        "def precompute_pos_cis(dim: int, end: int = int(32 * 1024), theta: float = 1e6):\n",
        "    \"\"\"\n",
        "    Precomputes complex exponentials (cis) for rotary positional embeddings.\n",
        "\n",
        "    Args:\n",
        "        dim: Dimensionality of the embeddings.\n",
        "        end: Maximum sequence length.\n",
        "        theta: Scaling factor for frequencies.\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor: Precomputed complex exponentials.\n",
        "    \"\"\"\n",
        "    freqs = 1.0 / (theta ** (torch.arange(0, dim, 2)[: (dim // 2)].float() / dim))\n",
        "    t = torch.arange(end, device=freqs.device)  # type: ignore # Sequence indices\n",
        "    freqs = torch.outer(t, freqs).float()  # type: ignore # Outer product to get frequencies for each position\n",
        "    pos_cis = torch.polar(torch.ones_like(freqs), freqs)  # complex64 # Create complex exponentials\n",
        "    return pos_cis\n",
        "\n",
        "\n",
        "def apply_rotary_emb(xq, xk, pos_cis):\n",
        "    \"\"\"\n",
        "    Applies rotary positional embeddings to query (xq) and key (xk) tensors.\n",
        "\n",
        "    Args:\n",
        "        xq: Query tensor.\n",
        "        xk: Key tensor.\n",
        "        pos_cis: Precomputed complex exponentials.\n",
        "\n",
        "    Returns:\n",
        "        Tuple[torch.Tensor, torch.Tensor]: Query and key tensors with rotary embeddings applied.\n",
        "    \"\"\"\n",
        "\n",
        "    def unite_shape(pos_cis, x):\n",
        "        # Reshape pos_cis to have compatible dimensions with x for broadcasting.\n",
        "        ndim = x.ndim\n",
        "        assert 0 <= 1 < ndim\n",
        "        assert pos_cis.shape == (x.shape[1], x.shape[-1])\n",
        "        shape = [d if i == 1 or i == ndim - 1 else 1 for i, d in enumerate(x.shape)]\n",
        "        return pos_cis.view(*shape)\n",
        "\n",
        "    # Reshape and convert to complex numbers for efficient multiplication.\n",
        "    xq_ = torch.view_as_complex(xq.float().reshape(*xq.shape[:-1], -1, 2))\n",
        "    xk_ = torch.view_as_complex(xk.float().reshape(*xk.shape[:-1], -1, 2))\n",
        "    pos_cis = unite_shape(pos_cis, xq_)  # Reshape pos_cis for broadcasting\n",
        "    # Apply rotary embeddings via complex number multiplication.\n",
        "    xq_out = torch.view_as_real(xq_ * pos_cis).flatten(3)\n",
        "    xk_out = torch.view_as_real(xk_ * pos_cis).flatten(3)\n",
        "    return xq_out.type_as(xq), xk_out.type_as(xk)  # Ensure output type matches input\n",
        "\n",
        "\n",
        "def repeat_kv(x: torch.Tensor, n_rep: int) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Repeats the key-value pairs for multi-query attention.\n",
        "\n",
        "    Args:\n",
        "        x: Key-value tensor.\n",
        "        n_rep: Number of times to repeat each head.\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor: Key-value tensor with repeated heads.\n",
        "    \"\"\"\n",
        "    bs, slen, n_kv_heads, head_dim = x.shape\n",
        "    if n_rep == 1:\n",
        "        return x\n",
        "    # Expand and reshape to repeat the key-value heads.\n",
        "    return (\n",
        "        x[:, :, :, None, :]\n",
        "        .expand(bs, slen, n_kv_heads, n_rep, head_dim)\n",
        "        .reshape(bs, slen, n_kv_heads * n_rep, head_dim)\n",
        "    )\n",
        "\n",
        "\n",
        "class Attention(nn.Module):\n",
        "    \"\"\"\n",
        "    Implements multi-head attention with rotary positional embeddings.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, args: LMConfig):\n",
        "        super().__init__()\n",
        "        self.n_kv_heads = args.n_heads if args.n_kv_heads is None else args.n_kv_heads\n",
        "        assert args.n_heads % self.n_kv_heads == 0\n",
        "        self.n_local_heads = args.n_heads  # Total number of attention heads\n",
        "        self.n_local_kv_heads = self.n_kv_heads  # Number of key-value attention heads\n",
        "        self.n_rep = self.n_local_heads // self.n_local_kv_heads  # Repetition factor for key-value heads\n",
        "        self.head_dim = args.dim // args.n_heads  # Dimension of each attention head\n",
        "        # Linear projections for query, key, and value.\n",
        "        self.wq = nn.Linear(args.dim, args.n_heads * self.head_dim, bias=False)\n",
        "        self.wk = nn.Linear(args.dim, self.n_kv_heads * self.head_dim, bias=False)\n",
        "        self.wv = nn.Linear(args.dim, self.n_kv_heads * self.head_dim, bias=False)\n",
        "        self.wo = nn.Linear(args.n_heads * self.head_dim, args.dim, bias=False)  # Output projection\n",
        "        self.attn_dropout = nn.Dropout(args.dropout)  # Dropout for attention weights\n",
        "        self.resid_dropout = nn.Dropout(args.dropout)  # Dropout for the residual connection\n",
        "        self.dropout = args.dropout\n",
        "        # Check for Flash Attention availability (requires PyTorch >= 2.0).\n",
        "        self.flash = hasattr(torch.nn.functional, 'scaled_dot_product_attention') and args.flash_attn\n",
        "\n",
        "        # Causal mask for autoregressive decoding.\n",
        "        mask = torch.full((1, 1, args.max_seq_len, args.max_seq_len), float(\"-inf\"))\n",
        "        mask = torch.triu(mask, diagonal=1)  # Upper triangular mask\n",
        "        self.register_buffer(\"mask\", mask, persistent=False)  # Register as a buffer (not a parameter)\n",
        "\n",
        "    def forward(self,\n",
        "                x: torch.Tensor,\n",
        "                pos_cis: torch.Tensor,\n",
        "                past_key_value: Optional[Tuple[torch.Tensor, torch.Tensor]] = None,\n",
        "                use_cache=False):\n",
        "        bsz, seq_len, _ = x.shape\n",
        "        # Apply linear projections to get query, key, and value.\n",
        "        xq, xk, xv = self.wq(x), self.wk(x), self.wv(x)\n",
        "        # Reshape for multi-head attention.\n",
        "        xq = xq.view(bsz, seq_len, self.n_local_heads, self.head_dim)\n",
        "        xk = xk.view(bsz, seq_len, self.n_local_kv_heads, self.head_dim)\n",
        "        xv = xv.view(bsz, seq_len, self.n_local_kv_heads, self.head_dim)\n",
        "\n",
        "        # Apply rotary positional embeddings.\n",
        "        xq, xk = apply_rotary_emb(xq, xk, pos_cis)\n",
        "\n",
        "        # KV Cache implementation\n",
        "        if past_key_value is not None:\n",
        "            xk = torch.cat([past_key_value[0], xk], dim=1)  # Concatenate with cached keys\n",
        "            xv = torch.cat([past_key_value[1], xv], dim=1)  # Concatenate with cached values\n",
        "        past_kv = (xk, xv) if use_cache else None  # Store current keys and values for caching\n",
        "\n",
        "        # Repeat key-value pairs for multi-query attention.\n",
        "        xq, xk, xv = (\n",
        "            xq.transpose(1, 2),\n",
        "            repeat_kv(xk, self.n_rep).transpose(1, 2),\n",
        "            repeat_kv(xv, self.n_rep).transpose(1, 2)\n",
        "        )\n",
        "\n",
        "        # Attention mechanism selection: Flash Attention (if available) or standard attention.\n",
        "        if self.flash and seq_len != 1:\n",
        "            dropout_p = self.dropout if self.training else 0.0  # Dropout only during training\n",
        "            output = F.scaled_dot_product_attention(\n",
        "                xq, xk, xv,\n",
        "                attn_mask=None,  # No explicit mask needed (causal masking is handled internally)\n",
        "                dropout_p=dropout_p,\n",
        "                is_causal=True  # Enforce causal attention\n",
        "            )\n",
        "        else:\n",
        "            # Standard attention\n",
        "            scores = (xq @ xk.transpose(-2, -1)) / math.sqrt(self.head_dim)  # Calculate attention scores\n",
        "            scores += self.mask[:, :, :seq_len, :seq_len]  # Apply causal mask\n",
        "            scores = F.softmax(scores.float(), dim=-1).type_as(xq)  # Softmax to get attention weights\n",
        "            scores = self.attn_dropout(scores)  # Apply dropout\n",
        "            output = scores @ xv  # Weighted sum of values\n",
        "\n",
        "        # Reshape and apply output projection.\n",
        "        output = output.transpose(1, 2).reshape(bsz, seq_len, -1)\n",
        "        output = self.resid_dropout(self.wo(output))\n",
        "        return output, past_kv\n",
        "\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "    \"\"\"\n",
        "    Implements the feedforward network (FFN) used in each transformer block.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, config: LMConfig):\n",
        "        super().__init__()\n",
        "        # Compute hidden dimension for FFN.\n",
        "        if config.hidden_dim is None:\n",
        "            hidden_dim = 4 * config.dim\n",
        "            hidden_dim = int(2 * hidden_dim / 3)\n",
        "            config.hidden_dim = config.multiple_of * ((hidden_dim + config.multiple_of - 1) // config.multiple_of)\n",
        "        # Linear layers with SiLU activation.\n",
        "        self.w1 = nn.Linear(config.dim, config.hidden_dim, bias=False)\n",
        "        self.w2 = nn.Linear(config.hidden_dim, config.dim, bias=False)\n",
        "        self.w3 = nn.Linear(config.dim, config.hidden_dim, bias=False)\n",
        "        self.dropout = nn.Dropout(config.dropout)  # Dropout after the FFN\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Apply FFN transformation:  x -> SiLU(xW1) * (xW3) -> (result)W2 -> dropout\n",
        "        return self.dropout(self.w2(F.silu(self.w1(x)) * self.w3(x)))\n",
        "\n",
        "\n",
        "\n",
        "class TransformerBlock(nn.Module):\n",
        "    \"\"\"\n",
        "    Implements a single transformer block.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, layer_id: int, config: LMConfig):\n",
        "        super().__init__()\n",
        "        self.n_heads = config.n_heads\n",
        "        self.dim = config.dim\n",
        "        self.head_dim = config.dim // config.n_heads\n",
        "        self.attention = Attention(config)  # Multi-head attention\n",
        "\n",
        "        self.layer_id = layer_id\n",
        "        # Layer normalization for attention and FFN.\n",
        "        self.attention_norm = RMSNorm(config.dim, eps=config.norm_eps)\n",
        "        self.ffn_norm = RMSNorm(config.dim, eps=config.norm_eps)\n",
        "        # Feedforward network.\n",
        "        self.feed_forward = FeedForward(config)\n",
        "\n",
        "    def forward(self, x, pos_cis, past_key_value=None, use_cache=False):\n",
        "        # Attention block with residual connection.\n",
        "        h_attn, past_kv = self.attention(\n",
        "            self.attention_norm(x),  # Normalize input before attention\n",
        "            pos_cis,  # Rotary positional embeddings\n",
        "            past_key_value=past_key_value,  # Pass cached key-value pairs\n",
        "            use_cache=use_cache  # Whether to use caching\n",
        "        )\n",
        "        h = x + h_attn  # Residual connection\n",
        "        # Feedforward block with residual connection.\n",
        "        out = h + self.feed_forward(self.ffn_norm(h))  # Normalize input before FFN\n",
        "        return out, past_kv\n",
        "\n",
        "\n",
        "class TransformerLM(PreTrainedModel):\n",
        "    \"\"\"\n",
        "    The main Transformer language model.\n",
        "    \"\"\"\n",
        "    config_class = LMConfig  # Use LMConfig as the configuration class\n",
        "\n",
        "    def __init__(self, params: LMConfig = None):\n",
        "        self.params = params or LMConfig()  # Use default config if none provided\n",
        "        super().__init__(self.params)  # Initialize PreTrainedModel\n",
        "        self.vocab_size, self.n_layers = params.vocab_size, params.n_layers\n",
        "        # Token embeddings.\n",
        "        self.tok_embeddings = nn.Embedding(params.vocab_size, params.dim)\n",
        "        self.dropout = nn.Dropout(params.dropout)  # Dropout after embeddings\n",
        "        # Transformer blocks.\n",
        "        self.layers = nn.ModuleList([TransformerBlock(l, params) for l in range(self.n_layers)])\n",
        "        # Final layer normalization.\n",
        "        self.norm = RMSNorm(params.dim, eps=params.norm_eps)\n",
        "        # Output layer (maps from hidden states to logits).\n",
        "        self.output = nn.Linear(params.dim, params.vocab_size, bias=False)\n",
        "        # Tie token embeddings and output weights.\n",
        "        #self.tok_embeddings.weight = self.output.weight\n",
        "        # Precompute and register rotary positional embeddings.\n",
        "        self.register_buffer(\"pos_cis\",\n",
        "                             precompute_pos_cis(dim=params.dim // params.n_heads, theta=params.rope_theta),\n",
        "                             persistent=False)\n",
        "        self.OUT = CausalLMOutputWithPast()  # Use CausalLMOutputWithPast for output\n",
        "\n",
        "    def forward(self,\n",
        "                input_ids: Optional[torch.Tensor] = None,\n",
        "                past_key_values: Optional[List[Tuple[torch.Tensor, torch.Tensor]]] = None,\n",
        "                use_cache: bool = False,\n",
        "                **args):\n",
        "\n",
        "        past_key_values = past_key_values or [None] * len(self.layers)  # Initialize empty cache if None\n",
        "        start_pos = args.get('start_pos', 0)  # Get starting position for sequence generation\n",
        "\n",
        "        h = self.dropout(self.tok_embeddings(input_ids))  # Get token embeddings and apply dropout\n",
        "        pos_cis = self.pos_cis[start_pos:start_pos + input_ids.size(1)]  # Get relevant rotary embeddings\n",
        "\n",
        "        past_kvs = []  # Store past key-value pairs for caching\n",
        "        for l, layer in enumerate(self.layers):\n",
        "            h, past_kv = layer(\n",
        "                h, pos_cis,\n",
        "                past_key_value=past_key_values[l],  # Pass cached key-value pairs\n",
        "                use_cache=use_cache\n",
        "            )\n",
        "            past_kvs.append(past_kv)  # Store updated key-value pairs\n",
        "\n",
        "        logits = self.output(self.norm(h))  # Final layer normalization and output projection\n",
        "\n",
        "        # Set output attributes using __setitem__\n",
        "        self.OUT.__setitem__('logits', logits)\n",
        "        self.OUT.__setitem__('past_key_values', past_kvs)\n",
        "        return self.OUT  # Return CausalLMOutputWithPast object\n",
        "\n",
        "    #@torch.inference_mode()\n",
        "    def generate(self, input_ids, eos_token_id=2, max_new_tokens=1024, temperature=0.75, top_p=0.90,\n",
        "                 stream=False, rp=1., use_cache=True, pad_token_id=0, **args):\n",
        "        \"\"\"\n",
        "        Generates text from the model.\n",
        "\n",
        "        Args:\n",
        "            input_ids: Initial input token IDs.\n",
        "            eos_token_id: End-of-sequence token ID.\n",
        "            max_new_tokens: Maximum number of tokens to generate.\n",
        "            temperature: Sampling temperature.\n",
        "            top_p: Top-p (nucleus) sampling probability.\n",
        "            stream: Whether to stream the output (yield tokens one by one).\n",
        "            rp: Repetition penalty.\n",
        "            use_cache: Whether to use key-value caching.\n",
        "            pad_token_id: pad token id.\n",
        "            **args: Additional arguments passed to the forward method.\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Generated sequence of token IDs.\n",
        "                         (if stream=False)\n",
        "            Generator[torch.Tensor, None, None]:  Generated tokens.\n",
        "                                        (if stream=True)\n",
        "        \"\"\"\n",
        "        # Stream generation\n",
        "        if stream:\n",
        "            return self._stream(input_ids, eos_token_id, max_new_tokens, temperature, top_p, rp, use_cache, **args)\n",
        "\n",
        "        # Direct generation (collects all tokens at once)\n",
        "        generated = []\n",
        "        for i in range(input_ids.size(0)):\n",
        "            # remove padding\n",
        "            non_pad = input_ids[i][input_ids[i] != pad_token_id].unsqueeze(0)\n",
        "            # generate tokens\n",
        "            out = self._stream(non_pad, eos_token_id, max_new_tokens, temperature, top_p, rp, use_cache, **args)\n",
        "            # collect the generated token one-by-one\n",
        "            tokens_list = [tokens[:, -1:] for tokens in out]\n",
        "            gen = torch.cat(tokens_list, dim=-1) if tokens_list else non_pad\n",
        "            # concat the input and generated tokens together\n",
        "            full_sequence = torch.cat([non_pad, gen], dim=-1)\n",
        "            generated.append(full_sequence)\n",
        "        # find the longest sequence\n",
        "        max_length = max(seq.size(1) for seq in generated)\n",
        "        # padding the sequences\n",
        "        generated = [\n",
        "            torch.cat(\n",
        "                [seq, torch.full((1, max_length - seq.size(1)), pad_token_id, dtype=seq.dtype, device=seq.device)],\n",
        "                dim=-1)\n",
        "            for seq in generated\n",
        "        ]\n",
        "        # concatenate all generated tensors together\n",
        "        return torch.cat(generated, dim=0)\n",
        "\n",
        "    def _stream(self, input_ids, eos_token_id, max_new_tokens, temperature, top_p, rp, use_cache, **args):\n",
        "        \"\"\"\n",
        "        Helper function for streaming text generation.\n",
        "        \"\"\"\n",
        "        start, first_seq, past_kvs = input_ids.shape[1], True, None\n",
        "        while input_ids.shape[1] < max_new_tokens - 1:\n",
        "            if first_seq or not use_cache:\n",
        "                # For the first sequence or when not using cache, process the entire input sequence.\n",
        "                out, first_seq = self(input_ids, past_key_values=past_kvs, use_cache=use_cache, **args), False\n",
        "            else:\n",
        "                # For subsequent sequences with caching, process only the last token.\n",
        "                out = self(input_ids[:, -1:], past_key_values=past_kvs, use_cache=use_cache,\n",
        "                           start_pos=input_ids.shape[1] - 1, **args)\n",
        "            logits, past_kvs = out.logits[:, -1, :], out.past_key_values  # Get logits and updated cache\n",
        "\n",
        "            # Apply repetition penalty.\n",
        "            logits[:, list(set(input_ids.tolist()[0]))] /= rp\n",
        "\n",
        "            # Apply temperature scaling.\n",
        "            logits /= (temperature + 1e-9)\n",
        "\n",
        "            # Apply top-p (nucleus) sampling.\n",
        "            if top_p is not None and top_p < 1.0:\n",
        "                sorted_logits, sorted_indices = torch.sort(logits, descending=True, dim=-1)\n",
        "                sorted_probs = F.softmax(sorted_logits, dim=-1)\n",
        "                cumulative_probs = torch.cumsum(sorted_probs, dim=-1)\n",
        "                sorted_indices_to_remove = cumulative_probs > top_p\n",
        "                sorted_indices_to_remove[:, 1:] = sorted_indices_to_remove[:, :-1].clone()\n",
        "                sorted_indices_to_remove[:, 0] = False\n",
        "                indices_to_remove = sorted_indices_to_remove.scatter(1, sorted_indices, sorted_indices_to_remove)\n",
        "                logits[indices_to_remove] = -float('Inf')  # Set probabilities to -inf for filtered tokens\n",
        "\n",
        "            # Sample the next token.\n",
        "            input_ids_next = torch.multinomial(F.softmax(logits, dim=-1), num_samples=1)\n",
        "            input_ids = torch.cat((input_ids, input_ids_next), dim=1)  # Append the new token to the sequence\n",
        "            yield input_ids[:, start:]  # Yield the generated tokens (excluding the initial input)\n",
        "\n",
        "            # Break if EOS token is generated.\n",
        "            if input_ids_next.item() == eos_token_id:\n",
        "                break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "je-8Mku0PEl2"
      },
      "source": [
        "# boucle d'entrainement"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PFi-bL4zPEl2"
      },
      "outputs": [],
      "source": [
        "def get_lr(current_step, total_steps, lr):\n",
        "    \"\"\"Calculates the learning rate using a cosine schedule.\"\"\"\n",
        "    return lr / 10 + 0.5 * lr * (1 + math.cos(math.pi * current_step / total_steps))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i0iDQioaPEl2"
      },
      "outputs": [],
      "source": [
        "# Instantiate the model\n",
        "# device = \"cpu\"\n",
        "device = \"cuda\"\n",
        "lm_config = LMConfig() #max_seq_len=15)\n",
        "\n",
        "# Load the tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
        "tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
        "lm_config.vocab_size = tokenizer.vocab_size+1\n",
        "\n",
        "model = TransformerLM(lm_config)\n",
        "model =toch.compile(model) #https://ai.gopubby.com/torch-compile-how-it-makes-pytorch-models-so-fast-d8362488911f\n",
        "model = model.to(device) # Move the model to the GPU if available\n",
        "\n",
        "# Create the training dataset\n",
        "train_ds = PretrainDataset(\"petrain_data.jsonl\", tokenizer, max_length=lm_config.max_seq_len)\n",
        "\n",
        "# Create the data loader\n",
        "train_loader = DataLoader(train_ds, batch_size=8, shuffle=True, drop_last=False)\n",
        "\n",
        "# Define the optimizer (AdamW is a good choice)\n",
        "optimizer = optim.AdamW(model.parameters(), lr=5e-4)\n",
        "\n",
        "# Define the loss function (cross-entropy)\n",
        "loss_fct = nn.CrossEntropyLoss(reduction='none')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fwBkwYLZPEl3",
        "outputId": "51517818-026a-454e-ebbf-344eb7c356f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359,
          "referenced_widgets": [
            "6a64df9b5d2a401d89818853682e5981",
            "f0110d7bde744f7dbfc9f5335a1bdc2b",
            "69960e3c38f04639875add1a8870b785",
            "693ea7c4a79d4007a9a4e854038e2db3",
            "43d8bf58ff974e16abef72ce19e65c94",
            "8bf607fbd6a949ae9b3665aec0a5e069",
            "1e4d2bcd27464f47a7fc4569642d5b7e",
            "d43438530f654f39a20cb08dcd8f8413",
            "555b3f80c0174e41ac8e0035234645e6",
            "db9668651a074f92ae0c64059367ad99",
            "bef2afc588c9435185b036908bbbaa44",
            "d5826a9a319e41b080bb190f340a1949",
            "efe45d974cac4a3488b98f0decaa7c8d",
            "339f878ea61b48e59b7e9474aa105582",
            "630d0b33a5bc4785af4526af724ca9c5",
            "a5061f7d260d46f9ab446aca0301b5b5",
            "8f2cc0b914e74d7394e668de7523197d",
            "7e55aa4b8e44480b88a1e45cccd68038",
            "36e86bc168c94a49b5b5dd450e70d6ce",
            "1bd0f4f53eed4ef0a33bd7de557ab658",
            "8acc287ea3e341019a3024f850931ec1",
            "b47d5577f764487cbecc113619d439c4",
            "2e6ef86519004e5b9b0d5e9f0d8ac805",
            "79f8fd8f6d24464ebee948e95d131aec",
            "a9df8cdfac6e45e08bd7ba8aa8605982",
            "a70ff9ebfec849fb8d709d065a60b63b",
            "aff6187a7469410b89655ca1e6254d3c",
            "b1566efd947b46bb8206cbaa24fdd674",
            "0ac290b9f84a4cd1ac53ef283d7027b7",
            "65bceda90fea46f49c512416f74e4a3c",
            "649f176907324c12adf28306388a57e3",
            "646bb13991a84c43b7d9dce412d990a4",
            "f09a3fdd52b4418e9f80225afa9e6606",
            "667cc1927ee94afea20aa404a1d3b99c",
            "28ad7a336a4f432db4843f818411cd37",
            "eabc837ca7a34515aa2d4af855361f9e",
            "9f081a7cc71d46ab9a083f77effc3802",
            "53736167790a43f186200e72f53f9fb1",
            "db5bda784be24b18b13c39fbf75bfed6",
            "057900281cae40d1b1fa4c39332b02c2",
            "d815cdbbe1d44c9fbce8166fbe919d66",
            "64f58fbaaeee42c3bc80e6a7f80c1703",
            "a9296383f65e425aa212cdd6a5e49cd3",
            "41f3e6c96865432682837d65defe8721"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/391 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6a64df9b5d2a401d89818853682e5981"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "save step  99\n",
            "save step  199\n",
            "save step  299\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/391 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d5826a9a319e41b080bb190f340a1949"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "save step  99\n",
            "save step  199\n",
            "save step  299\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/391 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2e6ef86519004e5b9b0d5e9f0d8ac805"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "save step  99\n",
            "save step  199\n",
            "save step  299\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/391 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "667cc1927ee94afea20aa404a1d3b99c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "save step  99\n",
            "save step  199\n",
            "save step  299\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "from tqdm.notebook import tqdm\n",
        "epochs = 4 # You can adjust the number of epochs\n",
        "iter_per_epoch = len(train_loader) #how many batches are there\n",
        "accumulation_steps = 8 #for gradient accumulation\n",
        "grad_clip = 1.0 #for gradient clipping\n",
        "\n",
        "model.train()# set back to training mode.\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    start_time = time.time()\n",
        "    #for step, (X, Y, loss_mask) in enumerate(train_loader):\n",
        "    step = 0\n",
        "    batch_iter = tqdm(train_loader)\n",
        "    for (X, Y, loss_mask) in batch_iter:\n",
        "        X = X.to(\"cuda\")\n",
        "        Y = Y.to(\"cuda\")\n",
        "        loss_mask = loss_mask.to(\"cuda\")\n",
        "\n",
        "        # Calculate the learning rate for the current step\n",
        "        lr = get_lr(epoch * iter_per_epoch + step, epochs * iter_per_epoch, 5e-4)\n",
        "        for param_group in optimizer.param_groups:\n",
        "            param_group['lr'] = lr\n",
        "\n",
        "        # Forward pass\n",
        "        res = model(X)\n",
        "\n",
        "        # Calculate the loss\n",
        "        loss = loss_fct(\n",
        "            res.logits.view(-1, res.logits.size(-1)),\n",
        "            Y.view(-1)\n",
        "        ).view(Y.size())\n",
        "        loss = (loss * loss_mask).sum() / loss_mask.sum()\n",
        "        loss = loss/accumulation_steps # divided by accumulation steps\n",
        "\n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "        batch_iter.set_postfix(**{'loss (batch)': loss.item() * accumulation_steps})\n",
        "        if (step + 1) % accumulation_steps == 0:\n",
        "            # Gradient Clipping\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n",
        "            # Update the model's parameters\n",
        "            optimizer.step()\n",
        "            # Reset the gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "        # if step % 100 == 0:\n",
        "        #     spend_time = time.time() - start_time\n",
        "        #     print(\n",
        "        #         'Epoch:[{}/{}]({}/{}) loss:{:.3f} lr:{:.12f} epoch_Time:{}min:'.format(\n",
        "        #             epoch + 1,\n",
        "        #             epochs,\n",
        "        #             step,\n",
        "        #             iter_per_epoch,\n",
        "        #             loss.item() * accumulation_steps,\n",
        "        #             optimizer.param_groups[-1]['lr'],\n",
        "        #             spend_time / (step + 1) * iter_per_epoch // 60 - spend_time //60))\n",
        "\n",
        "        if(step + 1) % 100 == 0:\n",
        "            print(\"save step \",step )\n",
        "            model.eval() #set to evaluation mode\n",
        "            torch.save(model.state_dict(), \"pretrain_model.pth\") #save state dict\n",
        "            model.train()# set back to training mode.\n",
        "        step = step+1\n",
        "\n",
        "model.eval() #set to evaluation mode\n",
        "torch.save(model.state_dict(), \"pretrain_model.pth\") #save state dict\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8HETbecaPEl3",
        "outputId": "67842e02-57d4-4b52-c14e-591d1c3d58d1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1, 14]) torch.Size([1, 14])\n",
            "tensor([[50256,    40,  1053,  2982,  1049,  1243,   546,   366,  2202, 22183,\n",
            "             1,   416,  7970,  2677]])\n",
            "tensor([[   40,  1053,  2982,  1049,  1243,   546,   366,  2202, 22183,     1,\n",
            "           416,  7970,  2677,   290]])\n",
            "tensor([   40,  1053,  2982,  1049,  1243,   546,   366,  2202, 22183,     1,\n",
            "          416,  7970,  2677,   290])\n",
            "torch.Size([1, 14, 50258])\n",
            "torch.Size([14, 50258])\n"
          ]
        }
      ],
      "source": [
        "# X,Y,loss_mask = next(iter(train_loader))\n",
        "# print(X.shape, Y.shape)\n",
        "# X = X.to(device)\n",
        "# Y = Y.to(device)\n",
        "# loss_mask = loss_mask.to(device)\n",
        "\n",
        "# # Forward pass\n",
        "# res = model(X)\n",
        "\n",
        "# # Calculate the loss\n",
        "# loss = loss_fct(\n",
        "#     res.logits.view(-1, res.logits.size(-1)),\n",
        "#     Y.view(-1)\n",
        "# ).view(Y.size())\n",
        "\n",
        "# print(X)\n",
        "# print(Y)\n",
        "# print(Y.view(-1))\n",
        "# print(res.logits.shape)\n",
        "# print(res.logits.view(-1, res.logits.size(-1)).shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yHlnDfQ_PEl4",
        "outputId": "69dc0119-1fa0-4e1d-b18f-68074c25283e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[16594,   257,  7322,   546,   262,  4034,   286, 18207, 20351]],\n",
            "       device='cuda:0')\n",
            "Write a paragraph about the benefits of practicing yoga.\n",
            "If us know the option is essential to take using cl an effective way to come up your goals.\n"
          ]
        }
      ],
      "source": [
        "prompt = \"Write a paragraph about the benefits of practicing yoga\"\n",
        "max_new_tokens=512\n",
        "temperature=0.85\n",
        "top_p=0.9\n",
        "input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(device)\n",
        "print(input_ids)\n",
        "output_ids = model.generate(input_ids, max_new_tokens=max_new_tokens, temperature=temperature, top_p=top_p,\n",
        "                                eos_token_id=tokenizer.eos_token_id)\n",
        "print(tokenizer.decode(output_ids[0], skip_special_tokens=True))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "9sVajPHqmYLt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(sum(p.numel() for p in model.parameters()))\n",
        "print(model)"
      ],
      "metadata": {
        "id": "SuWlCCqEm7oe",
        "outputId": "3a38d188-e4f0-46fe-ab88-7cb9725d0eba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TransformerLM(\n",
            "  (tok_embeddings): Embedding(50258, 512)\n",
            "  (dropout): Dropout(p=0.0, inplace=False)\n",
            "  (layers): ModuleList(\n",
            "    (0-7): 8 x TransformerBlock(\n",
            "      (attention): Attention(\n",
            "        (wq): Linear(in_features=512, out_features=512, bias=False)\n",
            "        (wk): Linear(in_features=512, out_features=128, bias=False)\n",
            "        (wv): Linear(in_features=512, out_features=128, bias=False)\n",
            "        (wo): Linear(in_features=512, out_features=512, bias=False)\n",
            "        (attn_dropout): Dropout(p=0.0, inplace=False)\n",
            "        (resid_dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (attention_norm): RMSNorm()\n",
            "      (ffn_norm): RMSNorm()\n",
            "      (feed_forward): FeedForward(\n",
            "        (w1): Linear(in_features=512, out_features=1408, bias=False)\n",
            "        (w2): Linear(in_features=1408, out_features=512, bias=False)\n",
            "        (w3): Linear(in_features=512, out_features=1408, bias=False)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (norm): RMSNorm()\n",
            "  (output): Linear(in_features=512, out_features=50258, bias=False)\n",
            ")\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Bienvenue dans Colaboratory",
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "6ab559df54652bb95e07787d59a59d160dc53acec48e26b004f7b380e6f234b9"
      }
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6a64df9b5d2a401d89818853682e5981": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f0110d7bde744f7dbfc9f5335a1bdc2b",
              "IPY_MODEL_69960e3c38f04639875add1a8870b785",
              "IPY_MODEL_693ea7c4a79d4007a9a4e854038e2db3"
            ],
            "layout": "IPY_MODEL_43d8bf58ff974e16abef72ce19e65c94"
          }
        },
        "f0110d7bde744f7dbfc9f5335a1bdc2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8bf607fbd6a949ae9b3665aec0a5e069",
            "placeholder": "​",
            "style": "IPY_MODEL_1e4d2bcd27464f47a7fc4569642d5b7e",
            "value": "100%"
          }
        },
        "69960e3c38f04639875add1a8870b785": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d43438530f654f39a20cb08dcd8f8413",
            "max": 391,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_555b3f80c0174e41ac8e0035234645e6",
            "value": 391
          }
        },
        "693ea7c4a79d4007a9a4e854038e2db3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_db9668651a074f92ae0c64059367ad99",
            "placeholder": "​",
            "style": "IPY_MODEL_bef2afc588c9435185b036908bbbaa44",
            "value": " 391/391 [05:24&lt;00:00,  1.65it/s, loss (batch)=3.9]"
          }
        },
        "43d8bf58ff974e16abef72ce19e65c94": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8bf607fbd6a949ae9b3665aec0a5e069": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1e4d2bcd27464f47a7fc4569642d5b7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d43438530f654f39a20cb08dcd8f8413": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "555b3f80c0174e41ac8e0035234645e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "db9668651a074f92ae0c64059367ad99": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bef2afc588c9435185b036908bbbaa44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d5826a9a319e41b080bb190f340a1949": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_efe45d974cac4a3488b98f0decaa7c8d",
              "IPY_MODEL_339f878ea61b48e59b7e9474aa105582",
              "IPY_MODEL_630d0b33a5bc4785af4526af724ca9c5"
            ],
            "layout": "IPY_MODEL_a5061f7d260d46f9ab446aca0301b5b5"
          }
        },
        "efe45d974cac4a3488b98f0decaa7c8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8f2cc0b914e74d7394e668de7523197d",
            "placeholder": "​",
            "style": "IPY_MODEL_7e55aa4b8e44480b88a1e45cccd68038",
            "value": "100%"
          }
        },
        "339f878ea61b48e59b7e9474aa105582": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_36e86bc168c94a49b5b5dd450e70d6ce",
            "max": 391,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1bd0f4f53eed4ef0a33bd7de557ab658",
            "value": 391
          }
        },
        "630d0b33a5bc4785af4526af724ca9c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8acc287ea3e341019a3024f850931ec1",
            "placeholder": "​",
            "style": "IPY_MODEL_b47d5577f764487cbecc113619d439c4",
            "value": " 391/391 [05:23&lt;00:00,  1.65it/s, loss (batch)=3.78]"
          }
        },
        "a5061f7d260d46f9ab446aca0301b5b5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8f2cc0b914e74d7394e668de7523197d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7e55aa4b8e44480b88a1e45cccd68038": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "36e86bc168c94a49b5b5dd450e70d6ce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1bd0f4f53eed4ef0a33bd7de557ab658": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8acc287ea3e341019a3024f850931ec1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b47d5577f764487cbecc113619d439c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2e6ef86519004e5b9b0d5e9f0d8ac805": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_79f8fd8f6d24464ebee948e95d131aec",
              "IPY_MODEL_a9df8cdfac6e45e08bd7ba8aa8605982",
              "IPY_MODEL_a70ff9ebfec849fb8d709d065a60b63b"
            ],
            "layout": "IPY_MODEL_aff6187a7469410b89655ca1e6254d3c"
          }
        },
        "79f8fd8f6d24464ebee948e95d131aec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b1566efd947b46bb8206cbaa24fdd674",
            "placeholder": "​",
            "style": "IPY_MODEL_0ac290b9f84a4cd1ac53ef283d7027b7",
            "value": "100%"
          }
        },
        "a9df8cdfac6e45e08bd7ba8aa8605982": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_65bceda90fea46f49c512416f74e4a3c",
            "max": 391,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_649f176907324c12adf28306388a57e3",
            "value": 391
          }
        },
        "a70ff9ebfec849fb8d709d065a60b63b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_646bb13991a84c43b7d9dce412d990a4",
            "placeholder": "​",
            "style": "IPY_MODEL_f09a3fdd52b4418e9f80225afa9e6606",
            "value": " 391/391 [05:24&lt;00:00,  1.64it/s, loss (batch)=3.3]"
          }
        },
        "aff6187a7469410b89655ca1e6254d3c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b1566efd947b46bb8206cbaa24fdd674": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0ac290b9f84a4cd1ac53ef283d7027b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "65bceda90fea46f49c512416f74e4a3c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "649f176907324c12adf28306388a57e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "646bb13991a84c43b7d9dce412d990a4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f09a3fdd52b4418e9f80225afa9e6606": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "667cc1927ee94afea20aa404a1d3b99c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_28ad7a336a4f432db4843f818411cd37",
              "IPY_MODEL_eabc837ca7a34515aa2d4af855361f9e",
              "IPY_MODEL_9f081a7cc71d46ab9a083f77effc3802"
            ],
            "layout": "IPY_MODEL_53736167790a43f186200e72f53f9fb1"
          }
        },
        "28ad7a336a4f432db4843f818411cd37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_db5bda784be24b18b13c39fbf75bfed6",
            "placeholder": "​",
            "style": "IPY_MODEL_057900281cae40d1b1fa4c39332b02c2",
            "value": "100%"
          }
        },
        "eabc837ca7a34515aa2d4af855361f9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d815cdbbe1d44c9fbce8166fbe919d66",
            "max": 391,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_64f58fbaaeee42c3bc80e6a7f80c1703",
            "value": 391
          }
        },
        "9f081a7cc71d46ab9a083f77effc3802": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a9296383f65e425aa212cdd6a5e49cd3",
            "placeholder": "​",
            "style": "IPY_MODEL_41f3e6c96865432682837d65defe8721",
            "value": " 391/391 [05:25&lt;00:00,  1.64it/s, loss (batch)=2.34]"
          }
        },
        "53736167790a43f186200e72f53f9fb1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "db5bda784be24b18b13c39fbf75bfed6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "057900281cae40d1b1fa4c39332b02c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d815cdbbe1d44c9fbce8166fbe919d66": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "64f58fbaaeee42c3bc80e6a7f80c1703": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a9296383f65e425aa212cdd6a5e49cd3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "41f3e6c96865432682837d65defe8721": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}